{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  time   location  consumption  temperature\n",
      "0  2022-04-07 21:00:00     bergen     1.113325         -0.3\n",
      "1  2022-04-07 21:00:00       oslo     4.092830          1.0\n",
      "2  2022-04-07 21:00:00  stavanger     2.057858          1.3\n",
      "3  2022-04-07 21:00:00     tromsø     1.246582         -3.9\n",
      "4  2022-04-07 21:00:00  trondheim     1.970098         -2.8\n",
      "5  2022-04-07 22:00:00     bergen     1.050327          0.0\n",
      "6  2022-04-07 22:00:00       oslo     3.818095          0.4\n",
      "7  2022-04-07 22:00:00  stavanger     1.918996          0.8\n",
      "8  2022-04-07 22:00:00     tromsø     1.180321         -4.3\n",
      "9  2022-04-07 22:00:00  trondheim     1.839443         -3.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/cleaned/consumption_temp_cleaned.csv')\n",
    "#df = pd.read_csv('./data/cleaned/wo_helsingfors/consumption_temp_cleaned.csv')\n",
    "\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{datetime.date(2022, 1, 1): 'Første nyttårsdag', datetime.date(2022, 4, 14): 'Skjærtorsdag', datetime.date(2022, 4, 15): 'Langfredag', datetime.date(2022, 4, 17): 'Første påskedag', datetime.date(2022, 4, 18): 'Andre påskedag', datetime.date(2022, 5, 1): 'Arbeidernes dag', datetime.date(2022, 5, 17): 'Grunnlovsdag', datetime.date(2022, 5, 26): 'Kristi himmelfartsdag', datetime.date(2022, 6, 5): 'Første pinsedag', datetime.date(2022, 6, 6): 'Andre pinsedag', datetime.date(2022, 12, 25): 'Første juledag', datetime.date(2022, 12, 26): 'Andre juledag', datetime.date(2023, 1, 1): 'Første nyttårsdag', datetime.date(2023, 4, 6): 'Skjærtorsdag', datetime.date(2023, 4, 7): 'Langfredag', datetime.date(2023, 4, 9): 'Første påskedag', datetime.date(2023, 4, 10): 'Andre påskedag', datetime.date(2023, 5, 1): 'Arbeidernes dag', datetime.date(2023, 5, 17): 'Grunnlovsdag', datetime.date(2023, 5, 18): 'Kristi himmelfartsdag', datetime.date(2023, 5, 28): 'Første pinsedag', datetime.date(2023, 5, 29): 'Andre pinsedag', datetime.date(2023, 12, 25): 'Første juledag', datetime.date(2023, 12, 26): 'Andre juledag'}\n",
      "                     time     location  consumption  temperature        date  \\\n",
      "735   2022-04-14 00:00:00       bergen     0.872431          4.8  2022-04-14   \n",
      "736   2022-04-14 00:00:00         oslo     2.926252          2.2  2022-04-14   \n",
      "737   2022-04-14 00:00:00    stavanger     1.553943          6.7  2022-04-14   \n",
      "738   2022-04-14 00:00:00       tromsø     1.041738          0.7  2022-04-14   \n",
      "739   2022-04-14 00:00:00    trondheim     1.439675          1.0  2022-04-14   \n",
      "...                   ...          ...          ...          ...         ...   \n",
      "36397 2023-01-01 23:00:00  helsingfors     6.458000         -1.6  2023-01-01   \n",
      "36398 2023-01-01 23:00:00         oslo    13.608053         -5.0  2023-01-01   \n",
      "36399 2023-01-01 23:00:00    stavanger     6.191684          1.6  2023-01-01   \n",
      "36400 2023-01-01 23:00:00       tromsø     1.783693         -0.6  2023-01-01   \n",
      "36401 2023-01-01 23:00:00    trondheim     3.995556         -9.5  2023-01-01   \n",
      "\n",
      "       is_holiday  weekday  hour_of_day  weekday_hour  is_weekend  \\\n",
      "735          True        3            0             0           0   \n",
      "736          True        3            0             0           0   \n",
      "737          True        3            0             0           0   \n",
      "738          True        3            0             0           0   \n",
      "739          True        3            0             0           0   \n",
      "...           ...      ...          ...           ...         ...   \n",
      "36397        True        6           23           138           1   \n",
      "36398        True        6           23           138           1   \n",
      "36399        True        6           23           138           1   \n",
      "36400        True        6           23           138           1   \n",
      "36401        True        6           23           138           1   \n",
      "\n",
      "       consumption_lag_last_week  consumption_lag_5_days  \n",
      "735                          NaN                0.994595  \n",
      "736                          NaN                3.555068  \n",
      "737                          NaN                1.760671  \n",
      "738                          NaN                1.080560  \n",
      "739                          NaN                1.731136  \n",
      "...                          ...                     ...  \n",
      "36397                   6.518000                6.502000  \n",
      "36398                  13.055932               13.179159  \n",
      "36399                   6.013548                6.162472  \n",
      "36400                   1.920408                1.859572  \n",
      "36401                   3.433700                3.417272  \n",
      "\n",
      "[1512 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "### Holiday binary encoding\n",
    "import holidays\n",
    "\n",
    "# Convert 'time' to datetime\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Extract date from 'time'\n",
    "df['date'] = df['time'].dt.date\n",
    "\n",
    "# Get Norwegian holidays\n",
    "no_holidays = holidays.Norway(years = [2022, 2023])\n",
    "\n",
    "print(no_holidays)\n",
    "\n",
    "# Create a feature for whether or not the date is a holiday\n",
    "df['is_holiday'] = df['date'].isin(no_holidays)\n",
    "\n",
    "\n",
    "### Other time related features\n",
    "\n",
    "# Extracting weekday feature\n",
    "df['weekday'] = df['time'].dt.weekday\n",
    "\n",
    "# Creating features for time of day\n",
    "df['hour_of_day'] = df['time'].dt.hour\n",
    "\n",
    "# Create interaction for weekday and hour_of_day\n",
    "df['weekday_hour'] = df['weekday'] * df['hour_of_day']\n",
    "\n",
    "# Create a new feature 'is_weekend' cause consumptions are higher on weekends\n",
    "df['is_weekend'] = df['weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "### Lag feature\n",
    "\n",
    "# Lag features for how the consumption was 7 days earlier\n",
    "df['consumption_lag_last_week'] = df.sort_values('date').groupby(['hour_of_day', 'location'])['consumption'].shift(7)\n",
    "\n",
    "# Lag features for how the consumption was 5 days earlier since we only have \n",
    "# access to data going 5 days back\n",
    "df['consumption_lag_5_days'] = df.sort_values('date').groupby(['hour_of_day', 'location'])['consumption'].shift(5)\n",
    "\n",
    "\n",
    "# print(df.head(10))\n",
    "\n",
    "print(df[df['is_holiday'] == True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seasonality feature\n",
    "\n",
    "# Assuming that:\n",
    "# 1 represents spring (March, April, May),\n",
    "# 2 represents summer (June, July, August),\n",
    "# 3 represents fall (September, October, November), \n",
    "# 4 represents winter (December, January, February)\n",
    "seasons = {1: '4', 2: '4', 3: '1', 4: '1', 5: '1', 6: '2', 7: '2', 8: '2', 9: '3', 10: '3', 11: '3', 12: '4'}\n",
    "\n",
    "# Apply the mapping to the 'month' column\n",
    "df['season'] = df['time'].dt.month.map(seasons)\n",
    "\n",
    "# Create interaction for is_holiday == True and season == 4, since consumption\n",
    "# only goes up in the winder when it is a holiday\n",
    "df['holiday_season_winter'] = ((df['is_holiday'] == True) & (df['season'] == 4)).astype(int)\n",
    "\n",
    "\n",
    "### Temperature difference from the previous day at the same time\n",
    "\n",
    "# # If direction of change matters, we should keep neg/pos values (this is usually\n",
    "# # the case when working with data involving temperature differences)\n",
    "# # If only magnitude of change matters, we should take the absolute value\n",
    "# df['temperature_diff_prev_day'] = df.sort_values('date').groupby(['hour_of_day', 'location'])['temperature'].diff()\n",
    "\n",
    "\n",
    "### Moving averages for consumption over the past week\n",
    "\n",
    "# # We apply a transform function to each location. Since each row in the data\n",
    "# # is a  by hour, and each location has 24 hours of data for each day,\n",
    "# # we can apply a rolling window of 168 (24*7) to get the past week's consumption\n",
    "# # grouped by each location\n",
    "# df['consumption_ma_week'] = df.groupby('location')['consumption'].transform(lambda x: x.rolling(24*7).mean())\n",
    "\n",
    "\n",
    "### Rolling window statistics for consumption over the past week\n",
    "\n",
    "# df['consumption_max_week'] = df.groupby(['location'])['consumption'].transform(lambda x: x.rolling(24*7).max())\n",
    "# df['consumption_min_week'] = df.groupby(['location'])['consumption'].transform(lambda x: x.rolling(24*7).min())\n",
    "\n",
    "\n",
    "### Exponential smoothing for consumption\n",
    "\n",
    "# here x.ewm(alpha=0.5).mean() calculates the exponential weighted moving \n",
    "# average for consumption for each location. alpha=0.5 is the decay factor, \n",
    "# which controls the rate of decay. A large alpha will make the EWM more \n",
    "# responsive to recent values, while a small alpha will make the EWM respond \n",
    "# more to historical values. We can play around with this value.\n",
    "\n",
    "# Forgot to play around with this one, after doing so results were improved\n",
    "# seems like 0.93, weighting closer to recent data gives better result, any\n",
    "# higher and it overfits and lower is slightly worse MSE\n",
    "df['consumption_ewm_alpha_0.93'] = df.groupby(['location'])['consumption'].apply(lambda x: x.ewm(alpha=0.93).mean()).reset_index(level=0, drop=True)\n",
    "\n",
    "# Save results to csv\n",
    "df.to_csv('./data/cleaned/consumption_temp_w_features.csv', index=False)\n",
    "#df.to_csv('./data/cleaned/wo_helsingfors/consumption_temp_w_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to model by setting target = consumption, scaling, fitting model, etc...\n",
    "X = df.drop('consumption', axis=1)\n",
    "y = df['consumption']\n",
    "# ... and so on\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
